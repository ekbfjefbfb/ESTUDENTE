"""
Knowledge Extractor Service - IA para Extracci√≥n de Contexto
Analiza conversaciones y documentos para extraer conocimiento estructurado

Problema que resuelve:
- Informaci√≥n valiosa perdida en conversaciones largas
- Nadie recuerda qu√© se decidi√≥ o qui√©n debe hacer qu√©
- B√∫squeda manual de informaci√≥n consume horas
- Falta de documentaci√≥n actualizada

Features:
- extract_from_conversation(): Extrae tasks, decisions, action_items de conversaci√≥n
- analyze_meeting_transcript(): Convierte transcripci√≥n reuni√≥n en resumen estructurado
- detect_urgent_items(): Identifica items urgentes que requieren atenci√≥n
- generate_knowledge_base(): Crea/actualiza KB autom√°ticamente
- find_similar_discussions(): Encuentra discusiones similares hist√≥ricas
"""

import os
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import json

from services.gpt_service import GPTService

logger = logging.getLogger(__name__)


class KnowledgeExtractorService:
    """
    Service que usa IA (GPT) para extraer conocimiento estructurado
    de conversaciones no estructuradas
    
    Patrones detectados:
    - Tasks: "X, puedes hacer Y", "TODO: Z", "Pendiente implementar W"
    - Decisions: "Decidimos X", "Aprobado Y", "Se descart√≥ Z"
    - Deadlines: "para el viernes", "antes del lunes", "ASAP"
    - Assignments: "Juan se encarga", "@maria esto es para ti"
    - Questions: "¬øC√≥mo podemos...?", "¬øAlguien sabe...?"
    - Action Items: "Hay que hacer X", "Necesitamos Y"
    """
    
    def __init__(self):
        self.gpt_service = GPTService()
        logger.info("‚úÖ KnowledgeExtractorService iniciado")
    
    
    async def extract_from_conversation(
        self,
        messages: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Extrae conocimiento estructurado de una conversaci√≥n
        
        Args:
            messages: List[{
                sender: str,
                text: str,
                timestamp: datetime,
                channel: str
            }]
            context: {
                team_name: str,
                project_name: str,
                participants: List[str]
            }
        
        Returns:
            {
                summary: str,
                key_points: List[str],
                tasks: List[{
                    title: str,
                    assigned_to: str,
                    deadline: Optional[str],
                    priority: str
                }],
                decisions: List[{
                    title: str,
                    decided_by: List[str],
                    rationale: str
                }],
                action_items: List[{
                    item: str,
                    owner: str,
                    urgency: str
                }],
                questions: List[{
                    question: str,
                    asked_by: str,
                    answered: bool
                }],
                confidence: float
            }
        """
        logger.info(f"üîç Extrayendo conocimiento de {len(messages)} mensajes")
        
        # Construir prompt para GPT
        conversation_text = self._format_conversation_for_ai(messages)
        
        prompt = f"""Analiza la siguiente conversaci√≥n de equipo y extrae informaci√≥n estructurada.

CONTEXTO:
{json.dumps(context, indent=2) if context else "Sin contexto adicional"}

CONVERSACI√ìN:
{conversation_text}

EXTRAE Y FORMATEA EN JSON:
{{
    "summary": "Resumen de 2-3 l√≠neas de qu√© se discuti√≥",
    "key_points": ["Punto clave 1", "Punto clave 2", "..."],
    "tasks": [
        {{
            "title": "T√≠tulo tarea",
            "assigned_to": "Nombre persona o 'sin asignar'",
            "deadline": "Fecha mencionada o null",
            "priority": "high|medium|low"
        }}
    ],
    "decisions": [
        {{
            "title": "Decisi√≥n tomada",
            "decided_by": ["Nombre 1", "Nombre 2"],
            "rationale": "Por qu√© se tom√≥ esta decisi√≥n"
        }}
    ],
    "action_items": [
        {{
            "item": "Acci√≥n espec√≠fica",
            "owner": "Responsable o 'sin asignar'",
            "urgency": "urgent|normal|low"
        }}
    ],
    "questions": [
        {{
            "question": "Pregunta planteada",
            "asked_by": "Nombre",
            "answered": true/false
        }}
    ]
}}

IMPORTANTE:
- Si no hay items de una categor√≠a, devuelve array vac√≠o []
- Mant√©n t√≠tulos concisos y accionables
- Extrae nombres reales mencionados en la conversaci√≥n
- Identifica deadlines impl√≠citos ("para ma√±ana" = fecha espec√≠fica)
"""
        
        try:
            # Llamar a GPT
            response = await self.gpt_service.chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,  # M√°s determin√≠stico
                max_tokens=1500
            )
            
            # Parsear JSON response
            extracted = json.loads(response)
            
            # Calcular confidence basado en cantidad de info extra√≠da
            total_items = (
                len(extracted.get('tasks', [])) +
                len(extracted.get('decisions', [])) +
                len(extracted.get('action_items', [])) +
                len(extracted.get('key_points', []))
            )
            confidence = min(0.95, 0.5 + (total_items * 0.05))
            
            extracted['confidence'] = confidence
            
            logger.info(f"‚úÖ Extra√≠do conocimiento con confidence {confidence:.2f}: "
                       f"{len(extracted.get('tasks', []))} tasks, "
                       f"{len(extracted.get('decisions', []))} decisions")
            
            return extracted
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Error parseando respuesta GPT: {e}")
            return self._empty_extraction()
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo conocimiento: {e}")
            return self._empty_extraction()
    
    
    async def analyze_meeting_transcript(
        self,
        transcript: str,
        meeting_metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Analiza transcripci√≥n de reuni√≥n y genera resumen estructurado
        
        Args:
            transcript: Texto transcripci√≥n completa
            meeting_metadata: {
                title: str,
                date: datetime,
                participants: List[str],
                duration_minutes: int
            }
        
        Returns:
            {
                executive_summary: str,
                agenda_covered: List[str],
                decisions_made: List[Dict],
                action_items: List[Dict],
                key_discussions: List[Dict],
                next_steps: List[str],
                attendees_contributions: Dict[str, str]
            }
        """
        logger.info(f"üìù Analizando transcripci√≥n reuni√≥n: {meeting_metadata.get('title')}")
        
        prompt = f"""Analiza esta transcripci√≥n de reuni√≥n y genera un resumen ejecutivo estructurado.

METADATA:
- T√≠tulo: {meeting_metadata.get('title')}
- Fecha: {meeting_metadata.get('date')}
- Participantes: {', '.join(meeting_metadata.get('participants', []))}
- Duraci√≥n: {meeting_metadata.get('duration_minutes')} minutos

TRANSCRIPCI√ìN:
{transcript[:4000]}  # Limitar a ~4000 chars

GENERA JSON:
{{
    "executive_summary": "Resumen ejecutivo de 3-4 l√≠neas",
    "agenda_covered": ["Tema 1 discutido", "Tema 2 discutido", "..."],
    "decisions_made": [
        {{
            "decision": "Decisi√≥n espec√≠fica",
            "decided_by": "Nombre o 'equipo'",
            "impact": "high|medium|low"
        }}
    ],
    "action_items": [
        {{
            "action": "Acci√≥n espec√≠fica",
            "owner": "Responsable",
            "deadline": "Fecha o 'TBD'"
        }}
    ],
    "key_discussions": [
        {{
            "topic": "Tema discutido",
            "summary": "Resumen discusi√≥n",
            "participants": ["Qui√©nes participaron activamente"]
        }}
    ],
    "next_steps": ["Paso 1", "Paso 2", "..."],
    "attendees_contributions": {{
        "Nombre 1": "Breve resumen de su participaci√≥n",
        "Nombre 2": "Breve resumen de su participaci√≥n"
    }}
}}
"""
        
        try:
            response = await self.gpt_service.chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            
            result = json.loads(response)
            
            logger.info(f"‚úÖ Reuni√≥n analizada: {len(result.get('decisions_made', []))} decisiones, "
                       f"{len(result.get('action_items', []))} action items")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error analizando transcripci√≥n: {e}")
            return {
                'executive_summary': 'Error procesando transcripci√≥n',
                'agenda_covered': [],
                'decisions_made': [],
                'action_items': [],
                'key_discussions': [],
                'next_steps': [],
                'attendees_contributions': {}
            }
    
    
    async def detect_urgent_items(
        self,
        messages: List[Dict[str, Any]],
        threshold_hours: int = 24
    ) -> List[Dict[str, Any]]:
        """
        Detecta items urgentes que requieren atenci√≥n inmediata
        
        Args:
            messages: Mensajes recientes
            threshold_hours: Considerar urgente si deadline < X horas
        
        Returns:
            List[{
                item_type: str (task, question, blocker),
                title: str,
                urgency_score: float (0-1),
                reason: str,
                mentioned_by: str,
                requires_action_from: str,
                deadline: Optional[datetime]
            }]
        """
        logger.info(f"üö® Detectando items urgentes en {len(messages)} mensajes")
        
        conversation_text = self._format_conversation_for_ai(messages)
        
        prompt = f"""Identifica items URGENTES en esta conversaci√≥n que requieren atenci√≥n inmediata.

CONVERSACI√ìN:
{conversation_text}

CRITERIOS URGENCIA:
- Deadlines mencionados pr√≥ximos (<24h)
- Palabras clave: "urgente", "ASAP", "bloqueado", "cr√≠tico"
- Preguntas sin responder importantes
- Blockers mencionados
- Clientes esperando respuesta

GENERA JSON:
{{
    "urgent_items": [
        {{
            "item_type": "task|question|blocker|decision",
            "title": "T√≠tulo conciso",
            "urgency_score": 0.0-1.0,
            "reason": "Por qu√© es urgente",
            "mentioned_by": "Nombre",
            "requires_action_from": "Nombre o rol",
            "deadline": "Fecha espec√≠fica o null"
        }}
    ]
}}

DEVUELVE SOLO items verdaderamente urgentes (urgency_score > 0.7)
"""
        
        try:
            response = await self.gpt_service.chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                max_tokens=1000
            )
            
            result = json.loads(response)
            urgent_items = result.get('urgent_items', [])
            
            # Filtrar solo items con urgency_score > 0.7
            urgent_items = [item for item in urgent_items if item.get('urgency_score', 0) > 0.7]
            
            logger.info(f"‚úÖ Detectados {len(urgent_items)} items urgentes")
            return urgent_items
            
        except Exception as e:
            logger.error(f"‚ùå Error detectando urgentes: {e}")
            return []
    
    
    async def generate_knowledge_base_entry(
        self,
        topic: str,
        related_conversations: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Genera entrada de knowledge base basada en conversaciones relacionadas
        
        Args:
            topic: Tema (ej: "Deploy process", "API authentication")
            related_conversations: Conversaciones relacionadas al tema
        
        Returns:
            {
                title: str,
                summary: str,
                detailed_explanation: str,
                steps: List[str],
                common_issues: List[Dict],
                resources: List[str],
                last_updated: datetime,
                contributors: List[str]
            }
        """
        logger.info(f"üìö Generando KB entry para: {topic}")
        
        # Combinar conversaciones relacionadas
        combined_text = "\n\n".join([
            self._format_conversation_for_ai(conv.get('messages', []))
            for conv in related_conversations[:5]  # Limitar a 5 conversaciones
        ])
        
        prompt = f"""Genera una entrada de Knowledge Base sobre el tema "{topic}" bas√°ndote en estas conversaciones reales del equipo.

CONVERSACIONES:
{combined_text[:3000]}

GENERA JSON:
{{
    "title": "T√≠tulo claro y descriptivo",
    "summary": "Resumen de 2-3 l√≠neas",
    "detailed_explanation": "Explicaci√≥n detallada del tema",
    "steps": ["Paso 1", "Paso 2", "..."],
    "common_issues": [
        {{
            "issue": "Problema com√∫n",
            "solution": "C√≥mo resolverlo"
        }}
    ],
    "resources": ["Link 1", "Link 2", "..."],
    "tips": ["Tip 1", "Tip 2", "..."]
}}

IMPORTANTE:
- Usa informaci√≥n REAL de las conversaciones
- S√© espec√≠fico y pr√°ctico
- Incluye comandos, URLs, nombres reales mencionados
"""
        
        try:
            response = await self.gpt_service.chat_completion(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4,
                max_tokens=1500
            )
            
            result = json.loads(response)
            result['last_updated'] = datetime.now()
            result['contributors'] = list(set([
                msg.get('sender')
                for conv in related_conversations
                for msg in conv.get('messages', [])
                if msg.get('sender')
            ]))[:10]  # Top 10 contributors
            
            logger.info(f"‚úÖ KB entry generada: {result.get('title')}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error generando KB entry: {e}")
            return {
                'title': topic,
                'summary': 'Error generando contenido',
                'detailed_explanation': '',
                'steps': [],
                'common_issues': [],
                'resources': [],
                'last_updated': datetime.now(),
                'contributors': []
            }
    
    
    async def find_similar_discussions(
        self,
        query: str,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        Encuentra discusiones similares hist√≥ricas usando embeddings
        
        Args:
            query: Texto query o descripci√≥n del tema
            limit: M√°ximo resultados
        
        Returns:
            List[{
                conversation_id: str,
                title: str,
                similarity_score: float,
                date: datetime,
                participants: List[str],
                summary: str
            }]
        """
        logger.info(f"üîé Buscando discusiones similares a: {query}")
        
        # TODO: Implementar con embeddings (OpenAI Embeddings API)
        # 1. Generar embedding del query
        # 2. Query vector DB con conversaciones hist√≥ricas
        # 3. Calcular similaridad cosine
        # 4. Retornar top K resultados
        
        return []
    
    
    # ==========================================
    # HELPER METHODS
    # ==========================================
    
    def _format_conversation_for_ai(self, messages: List[Dict[str, Any]]) -> str:
        """Formatea mensajes para prompt IA"""
        formatted = []
        for msg in messages[:50]:  # Limitar a 50 mensajes
            sender = msg.get('sender', 'Unknown')
            text = msg.get('text', '')
            timestamp = msg.get('timestamp', '')
            
            formatted.append(f"[{timestamp}] {sender}: {text}")
        
        return "\n".join(formatted)
    
    
    def _empty_extraction(self) -> Dict[str, Any]:
        """Retorna estructura vac√≠a si falla extracci√≥n"""
        return {
            'summary': 'No se pudo extraer informaci√≥n',
            'key_points': [],
            'tasks': [],
            'decisions': [],
            'action_items': [],
            'questions': [],
            'confidence': 0.0
        }


# Singleton instance
_knowledge_extractor_service = None

def get_knowledge_extractor_service() -> KnowledgeExtractorService:
    """
    Obtiene instancia singleton de KnowledgeExtractorService
    """
    global _knowledge_extractor_service
    if _knowledge_extractor_service is None:
        _knowledge_extractor_service = KnowledgeExtractorService()
    return _knowledge_extractor_service
